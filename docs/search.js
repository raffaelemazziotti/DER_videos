window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "video_lib", "modulename": "video_lib", "kind": "module", "doc": "<h1 id=\"video_lib\">video_lib</h1>\n\n<p>A collection of tools for loading, managing, preprocessing, and presenting the\nDirect Emotional Response (DER) behavioral videos.</p>\n\n<p>Includes:</p>\n\n<ul>\n<li>TrgManager: Save/load trigger arrays (.npy)</li>\n<li>VideoManager: Low-level per-video movie extraction utilities</li>\n<li>VideoManagerArray: High-level experimental trial sequencing and access</li>\n</ul>\n\n<p>This module is intended for behavioral neuroscience experiments involving\nvicarious emotional response, upright vs. phase-scrambled stimuli, and\nper-trial movie extraction.</p>\n"}, {"fullname": "video_lib.TrgManager", "modulename": "video_lib", "qualname": "TrgManager", "kind": "class", "doc": "<h2 id=\"trgmanager\">TrgManager</h2>\n\n<p>Handle saving and loading of trigger arrays associated with video files.</p>\n\n<p>This utility class provides a simple interface for:</p>\n\n<ul>\n<li>Creating a <code>.npy</code> filename associated with a video or base name.</li>\n<li>Saving a 1-dimensional NumPy array to disk.</li>\n<li>Loading a previously saved trigger array.</li>\n<li>Checking whether the trigger file exists.</li>\n</ul>\n\n<h2 id=\"typical-usage\">Typical usage</h2>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">trg</span> <span class=\"o\">=</span> <span class=\"n\">TrgManager</span><span class=\"p\">(</span><span class=\"s2\">&quot;res/upright/video1.avi&quot;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">if</span> <span class=\"n\">trg</span><span class=\"o\">.</span><span class=\"n\">file_exists</span><span class=\"p\">():</span>\n<span class=\"gp\">... </span>    <span class=\"n\">trigger</span> <span class=\"o\">=</span> <span class=\"n\">trg</span><span class=\"o\">.</span><span class=\"n\">load_array</span><span class=\"p\">()</span>\n<span class=\"gp\">... </span><span class=\"k\">else</span><span class=\"p\">:</span>\n<span class=\"gp\">... </span>    <span class=\"n\">trg</span><span class=\"o\">.</span><span class=\"n\">save_array</span><span class=\"p\">(</span><span class=\"n\">my_trigger_vector</span><span class=\"p\">)</span>\n</code></pre>\n</div>\n\n<h2 id=\"notes\">Notes</h2>\n\n<p>The class enforces that the saved and loaded arrays must be monodimensional.\nThis ensures consistency with trigger vectors extracted from videos.</p>\n"}, {"fullname": "video_lib.TrgManager.__init__", "modulename": "video_lib", "qualname": "TrgManager.__init__", "kind": "function", "doc": "<p>Construct a TrgManager and derive the <code>.npy</code> filename.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>filename : str\n    The base filename or path associated with the trigger array.\n    If the input contains an extension, it is removed and replaced\n    with <code>.npy</code>. Otherwise, <code>.npy</code> is appended.</p>\n\n<h2 id=\"examples\">Examples</h2>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">TrgManager</span><span class=\"p\">(</span><span class=\"s2\">&quot;movie.avi&quot;</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">filename</span>\n<span class=\"go\">&#39;movie.npy&#39;</span>\n</code></pre>\n</div>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">TrgManager</span><span class=\"p\">(</span><span class=\"s2\">&quot;session&quot;</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">filename</span>\n<span class=\"go\">&#39;session.npy&#39;</span>\n</code></pre>\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">filename</span></span>)</span>"}, {"fullname": "video_lib.TrgManager.save_array", "modulename": "video_lib", "qualname": "TrgManager.save_array", "kind": "function", "doc": "<p>Save a 1-dimensional NumPy array to the trigger file.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>array : numpy.ndarray\n    The monodimensional array to be saved as <code>.npy</code>.</p>\n\n<h2 id=\"raises\">Raises</h2>\n\n<p>ValueError\n    If the array is not monodimensional.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<p>Arrays are saved using <code>numpy.save</code>. The file is overwritten if it exists.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">array</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.TrgManager.load_array", "modulename": "video_lib", "qualname": "TrgManager.load_array", "kind": "function", "doc": "<p>Load a monodimensional trigger array from disk.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>numpy.ndarray\n    The loaded 1-dimensional array.</p>\n\n<h2 id=\"raises\">Raises</h2>\n\n<p>ValueError\n    If the loaded array is not monodimensional.\nFileNotFoundError\n    If the trigger file does not exist.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<p>Files are loaded using <code>numpy.load</code>. The method enforces array shape.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.TrgManager.file_exists", "modulename": "video_lib", "qualname": "TrgManager.file_exists", "kind": "function", "doc": "<p>Check whether the trigger <code>.npy</code> file exists.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>bool\n    True if the file exists, otherwise False.</p>\n\n<h2 id=\"examples\">Examples</h2>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">trg</span> <span class=\"o\">=</span> <span class=\"n\">TrgManager</span><span class=\"p\">(</span><span class=\"s2\">&quot;video.avi&quot;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">trg</span><span class=\"o\">.</span><span class=\"n\">file_exists</span><span class=\"p\">()</span>\n<span class=\"go\">False</span>\n</code></pre>\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManagerArray", "modulename": "video_lib", "qualname": "VideoManagerArray", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManagerArray.__init__", "modulename": "video_lib", "qualname": "VideoManagerArray.__init__", "kind": "function", "doc": "<h2 id=\"videomanagerarray\">VideoManagerArray</h2>\n\n<p>A high-level container that loads multiple VideoManager objects from a dataset\norganized into <code>upright/</code> and <code>scrambled/</code> folders, generates an experiment-specific\ntrial sequence, and provides utilities for retrieving full trial movies across subjects.</p>\n\n<p>The class automates:</p>\n\n<ul>\n<li>Loading all upright and phase-scrambled videos in a given dataset folder.</li>\n<li>Creating paired VideoManager instances (upright and scrambled).</li>\n<li>Computing pre- and post-trial window sizes in frames, based on video FPS.</li>\n<li>Building the fixed set of trial combinations used in the experiment.</li>\n<li>Randomizing the trial order (optional).</li>\n<li>Providing access to (trial \u2192 movie segment) retrieval.</li>\n<li>Iterating the predefined stimulus sequence using <code>next_trial()</code>.</li>\n<li>Looking up valid trials for each subject.</li>\n</ul>\n\n<h2 id=\"typical-usage\">Typical usage</h2>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">vma</span> <span class=\"o\">=</span> <span class=\"n\">VideoManagerArray</span><span class=\"p\">(</span><span class=\"s2\">&quot;res&quot;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">t</span> <span class=\"o\">=</span> <span class=\"n\">vma</span><span class=\"o\">.</span><span class=\"n\">next_trial</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">movie</span><span class=\"p\">,</span> <span class=\"n\">trg</span> <span class=\"o\">=</span> <span class=\"n\">vma</span><span class=\"o\">.</span><span class=\"n\">get_trial_movie</span><span class=\"p\">(</span><span class=\"n\">t</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">VideoManagerArray</span><span class=\"o\">.</span><span class=\"n\">preview</span><span class=\"p\">(</span><span class=\"n\">movie</span><span class=\"p\">)</span>\n</code></pre>\n</div>\n\n<h2 id=\"dataset-structure\">Dataset Structure</h2>\n\n<p>folder/\n    upright/\n        <subject videos .avi>\n    scrambled/\n        <phase-scrambled videos .avi></p>\n\n<p>Each subject is represented by one upright video and one scrambled video.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">folder</span><span class=\"o\">=</span><span class=\"s1\">&#39;res&#39;</span>, </span><span class=\"param\"><span class=\"n\">pre_sec</span><span class=\"o\">=</span><span class=\"mi\">20</span>, </span><span class=\"param\"><span class=\"n\">post_sec</span><span class=\"o\">=</span><span class=\"mi\">20</span>, </span><span class=\"param\"><span class=\"n\">shuffle_trials</span><span class=\"o\">=</span><span class=\"kc\">True</span></span>)</span>"}, {"fullname": "video_lib.VideoManagerArray.upright", "modulename": "video_lib", "qualname": "VideoManagerArray.upright", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManagerArray.scrambled", "modulename": "video_lib", "qualname": "VideoManagerArray.scrambled", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManagerArray.vms", "modulename": "video_lib", "qualname": "VideoManagerArray.vms", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManagerArray.vms_ps", "modulename": "video_lib", "qualname": "VideoManagerArray.vms_ps", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManagerArray.folder", "modulename": "video_lib", "qualname": "VideoManagerArray.folder", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManagerArray.shuffle_trials", "modulename": "video_lib", "qualname": "VideoManagerArray.shuffle_trials", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManagerArray.pre", "modulename": "video_lib", "qualname": "VideoManagerArray.pre", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManagerArray.post", "modulename": "video_lib", "qualname": "VideoManagerArray.post", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManagerArray.fps", "modulename": "video_lib", "qualname": "VideoManagerArray.fps", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManagerArray.sequence_current", "modulename": "video_lib", "qualname": "VideoManagerArray.sequence_current", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManagerArray.get_trial_movie", "modulename": "video_lib", "qualname": "VideoManagerArray.get_trial_movie", "kind": "function", "doc": "<p>Extract the full movie segment for a given trial descriptor.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>trial : tuple\n    A 5-element trial description:\n        (subject_index, intensity, trial_number,\n         is_phase_scrambled, is_flipped)</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>trl : numpy.ndarray\n    A 4D array (frames \u00d7 H \u00d7 W \u00d7 channels) containing the movie segment.\n    The trigger pixel region (10\u00d710) is automatically cropped out.\ntrg : numpy.ndarray\n    A 1D array indicating the trigger time within the segment.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>pre/post time windows are automatically converted from seconds to frames.</li>\n<li>If <code>is_phase_scrambled</code> is True, frames are extracted from <code>self.vms_ps</code>.</li>\n<li>If <code>is_flipped</code> is True, frames are vertically flipped after cropping.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">trial</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManagerArray.get_valid_trials", "modulename": "video_lib", "qualname": "VideoManagerArray.get_valid_trials", "kind": "function", "doc": "<p>Return all valid trials for a given subject.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>sub : int\n    Subject index.\nshuffle : bool\n    If True, shuffle the order of returned valid trials.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>list of tuples\n    Each tuple is of the form (subject, intensity, trial_number).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">sub</span>, </span><span class=\"param\"><span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManagerArray.next_trial", "modulename": "video_lib", "qualname": "VideoManagerArray.next_trial", "kind": "function", "doc": "<p>Advance the internal pointer and return the next trial.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>tuple\n    The trial descriptor (subject, intensity, trial_number,\n    is_scrambled, is_flipped).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManagerArray.has_next_trial", "modulename": "video_lib", "qualname": "VideoManagerArray.has_next_trial", "kind": "function", "doc": "<p>Check whether more trials are available in the experiment sequence.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>bool\n    True if there is at least one more trial, False otherwise.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManagerArray.reset_trial", "modulename": "video_lib", "qualname": "VideoManagerArray.reset_trial", "kind": "function", "doc": "<p>Reset the trial iterator and optionally rebuild/shuffle the sequence.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>reshuffle : bool\n    If True, the sequence is rebuilt and optionally reshuffled.\nshuffle_trials : bool or None\n    Overrides the current shuffle setting if provided.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>None</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">reshuffle</span><span class=\"o\">=</span><span class=\"kc\">True</span>, </span><span class=\"param\"><span class=\"n\">shuffle_trials</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManagerArray.preview", "modulename": "video_lib", "qualname": "VideoManagerArray.preview", "kind": "function", "doc": "<p>Preview an array of frames using VideoManager.preview().</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">frames</span>, </span><span class=\"param\"><span class=\"n\">window</span><span class=\"o\">=</span><span class=\"s1\">&#39;Frames&#39;</span>, </span><span class=\"param\"><span class=\"n\">fps</span><span class=\"o\">=</span><span class=\"mi\">20</span>, </span><span class=\"param\"><span class=\"n\">repeat</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManagerArray.close", "modulename": "video_lib", "qualname": "VideoManagerArray.close", "kind": "function", "doc": "<p>Close all VideoManagers and release video resources.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>None</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager", "modulename": "video_lib", "qualname": "VideoManager", "kind": "class", "doc": "<h2 id=\"videomanager\">VideoManager</h2>\n\n<p>A high-level interface for loading, processing, analyzing, and previewing\nbehavioral videos recorded during stimulation experiments.</p>\n\n<p>The class supports:</p>\n\n<ul>\n<li>Video loading and property extraction (fps, resolution, frame count)</li>\n<li>Automatic trigger extraction from the first pixel or stored .npy file</li>\n<li>Trial detection, segmentation, and intensity assignment</li>\n<li>Habituation extraction</li>\n<li>Movement computation and visualization</li>\n<li>Previewing individual trials or full trial mosaics</li>\n<li>Generating videos or GIFs summarizing all trials</li>\n<li>Phase scrambling utilities for stimulus generation</li>\n</ul>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>video_path : str\n    Full path to the input video file.\npattern : list of int, optional\n    A cyclic list of stimulation intensity labels. Each detected trigger\n    is assigned an intensity based on this pattern.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<p>Trigger extraction:\n    The trigger is encoded as the BGR value of the first pixel in each frame.\n    Values &gt; 100 are considered \"trigger ON\".</p>\n\n<p>Trial definition:\n    The index of each detected trigger is stored in <code>self.trigger_timestamp</code>.\n    Trials are segmented relative to those timestamps.</p>\n\n<h2 id=\"usage-example\">Usage Example</h2>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">vm</span> <span class=\"o\">=</span> <span class=\"n\">VideoManager</span><span class=\"p\">(</span><span class=\"s2\">&quot;my_video.avi&quot;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">info</span> <span class=\"o\">=</span> <span class=\"n\">vm</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">frames</span><span class=\"p\">,</span> <span class=\"n\">trg</span> <span class=\"o\">=</span> <span class=\"n\">vm</span><span class=\"o\">.</span><span class=\"n\">get_trial</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">vm</span><span class=\"o\">.</span><span class=\"n\">preview_trial</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n</code></pre>\n</div>\n"}, {"fullname": "video_lib.VideoManager.__init__", "modulename": "video_lib", "qualname": "VideoManager.__init__", "kind": "function", "doc": "<p>Initialize the VideoManager, extract video metadata, load or compute\nthe trigger vector, detect trials, and build the intensity database.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>video_path : str\n    Path to the .avi video file.\npattern : list of int\n    A list representing the stimulation intensity pattern assigned\n    cyclically to each detected trigger.</p>\n\n<h2 id=\"behavior\">Behavior</h2>\n\n<ul>\n<li>Loads video file using OpenCV.</li>\n<li>Computes metadata: fps, resolution, total frames.</li>\n<li>Loads trigger array from disk if available, otherwise computes it by\nreading pixel (0,0) of each frame.</li>\n<li>Detects trigger timestamps via peak detection.</li>\n<li>Assigns stimulation intensities.</li>\n<li>Loads trial validity information from recordings.xlsx.</li>\n<li>Prepares helper attributes for visualization and preview.</li>\n</ul>\n\n<h2 id=\"side-effects\">Side Effects</h2>\n\n<ul>\n<li>Creates a <code>.npy</code> trigger file if not already present.</li>\n<li>Reads <code>recordings.xlsx</code> from the video's directory.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">video_path</span>, </span><span class=\"param\"><span class=\"n\">pattern</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">]</span></span>)</span>"}, {"fullname": "video_lib.VideoManager.video_path", "modulename": "video_lib", "qualname": "VideoManager.video_path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.rec", "modulename": "video_lib", "qualname": "VideoManager.rec", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.cap", "modulename": "video_lib", "qualname": "VideoManager.cap", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.total_frames", "modulename": "video_lib", "qualname": "VideoManager.total_frames", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.fps", "modulename": "video_lib", "qualname": "VideoManager.fps", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.frame_width", "modulename": "video_lib", "qualname": "VideoManager.frame_width", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.frame_height", "modulename": "video_lib", "qualname": "VideoManager.frame_height", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.resolution", "modulename": "video_lib", "qualname": "VideoManager.resolution", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.size_ratio", "modulename": "video_lib", "qualname": "VideoManager.size_ratio", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.trigger_norm", "modulename": "video_lib", "qualname": "VideoManager.trigger_norm", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.trigger_timestamp", "modulename": "video_lib", "qualname": "VideoManager.trigger_timestamp", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.trigger_tot", "modulename": "video_lib", "qualname": "VideoManager.trigger_tot", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.width", "modulename": "video_lib", "qualname": "VideoManager.width", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.height", "modulename": "video_lib", "qualname": "VideoManager.height", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.pattern", "modulename": "video_lib", "qualname": "VideoManager.pattern", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.stim_intensity", "modulename": "video_lib", "qualname": "VideoManager.stim_intensity", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.stimuli", "modulename": "video_lib", "qualname": "VideoManager.stimuli", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.recs", "modulename": "video_lib", "qualname": "VideoManager.recs", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.stim_db", "modulename": "video_lib", "qualname": "VideoManager.stim_db", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.habituation_inds", "modulename": "video_lib", "qualname": "VideoManager.habituation_inds", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.font", "modulename": "video_lib", "qualname": "VideoManager.font", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.font_scale", "modulename": "video_lib", "qualname": "VideoManager.font_scale", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.thickness", "modulename": "video_lib", "qualname": "VideoManager.thickness", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.color", "modulename": "video_lib", "qualname": "VideoManager.color", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.color_stim", "modulename": "video_lib", "qualname": "VideoManager.color_stim", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "video_lib.VideoManager.plot_trigger", "modulename": "video_lib", "qualname": "VideoManager.plot_trigger", "kind": "function", "doc": "<p>Plot the normalized trigger signal and detected trigger events.</p>\n\n<p>The trigger is derived from the first pixel of each frame. This method\nshows the binarized trigger vector and marks detected trigger peaks.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>ax : matplotlib.axes.Axes, optional\n    Axes on which to plot the trigger signal. If None, a new figure\n    and axes are created.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>matplotlib.axes.Axes\n    Axes containing the trigger plot.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">ax</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.plot_movement", "modulename": "video_lib", "qualname": "VideoManager.plot_movement", "kind": "function", "doc": "<p>Plot the movement index across a single trial.</p>\n\n<p>Movement is quantified as frame-to-frame difference using\n<code>frame_movements</code>. This method extracts a trial window, computes\nmovement indices for all frames, and plots them.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>trial_num : int\n    Trial index (0-based) to analyze.\npre : int, optional\n    Number of frames before the trigger to include.\npost : int, optional\n    Number of frames after the trigger to include.\nax : matplotlib.axes.Axes, optional\n    Axes on which to plot the movement index. If None, a new figure\n    and axes are created.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>matplotlib.axes.Axes\n    Axes containing the movement trace for the selected trial.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">trial_num</span>, </span><span class=\"param\"><span class=\"n\">pre</span><span class=\"o\">=</span><span class=\"mi\">60</span>, </span><span class=\"param\"><span class=\"n\">post</span><span class=\"o\">=</span><span class=\"mi\">60</span>, </span><span class=\"param\"><span class=\"n\">ax</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.plot_movement_matrix", "modulename": "video_lib", "qualname": "VideoManager.plot_movement_matrix", "kind": "function", "doc": "<p>Plot a 2D matrix of movement traces for all trials.</p>\n\n<p>The resulting figure has intensity on the rows and repetition number\non the columns. Each subplot shows the movement index for one trial.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>pre : int, optional\n    Frames before the trigger to include in each trial window.\npost : int, optional\n    Frames after the trigger to include in each trial window.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>matplotlib.figure.Figure\n    Figure containing the movement matrix.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">pre</span><span class=\"o\">=</span><span class=\"mi\">60</span>, </span><span class=\"param\"><span class=\"n\">post</span><span class=\"o\">=</span><span class=\"mi\">60</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.save_movement_matrix", "modulename": "video_lib", "qualname": "VideoManager.save_movement_matrix", "kind": "function", "doc": "<p>Compute and save the movement matrix for all trials to disk.</p>\n\n<p>This is similar to <code>plot_movement_matrix</code> but writes the figure\ndirectly to a file and closes the figure instead of displaying it.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>pre : int, optional\n    Frames before trigger to include in each trial window.\npost : int, optional\n    Frames after trigger to include in each trial window.\noutdir : str, optional\n    Output directory for the figure. Created if it does not exist.\nfmt : str, optional\n    Image format for saving (for example 'svg', 'png', 'pdf', 'jpg').</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>str\n    Path of the saved file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">pre</span><span class=\"o\">=</span><span class=\"mi\">60</span>, </span><span class=\"param\"><span class=\"n\">post</span><span class=\"o\">=</span><span class=\"mi\">60</span>, </span><span class=\"param\"><span class=\"n\">outdir</span><span class=\"o\">=</span><span class=\"s1\">&#39;graphs&#39;</span>, </span><span class=\"param\"><span class=\"n\">fmt</span><span class=\"o\">=</span><span class=\"s1\">&#39;svg&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.get_frame", "modulename": "video_lib", "qualname": "VideoManager.get_frame", "kind": "function", "doc": "<p>Retrieve a single frame by index.</p>\n\n<p>This performs a seek to frame i and then reads a single frame. It is\nrelatively slow for many random accesses.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>i : int\n    Index of the frame to retrieve (0-based).\nflip_vertical : bool, optional\n    If True, the frame is flipped vertically.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>numpy.ndarray or None\n    The requested frame as a HxWx3 array, or None if reading fails.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">i</span>, </span><span class=\"param\"><span class=\"n\">flip_vertical</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.get_frames", "modulename": "video_lib", "qualname": "VideoManager.get_frames", "kind": "function", "doc": "<p>Retrieve a sequence of frames as a 3D or 4D array.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>from_frame : int\n    Index of the first frame to retrieve (inclusive).\nto_frame : int\n    Index of the last frame to retrieve (exclusive).\nto_norm : bool, optional\n    If True, frames are converted to normalized grayscale and mean-centered.\nflip_vertical : bool, optional\n    If True, each frame is flipped vertically.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>numpy.ndarray\n    A 4D array of shape (N, H, W, 3) for RGB frames, or\n    (N, H, W) for normalized grayscale frames, where N is\n    to_frame - from_frame.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">from_frame</span>, </span><span class=\"param\"><span class=\"n\">to_frame</span>, </span><span class=\"param\"><span class=\"n\">to_norm</span><span class=\"o\">=</span><span class=\"kc\">False</span>, </span><span class=\"param\"><span class=\"n\">flip_vertical</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.get_habituation", "modulename": "video_lib", "qualname": "VideoManager.get_habituation", "kind": "function", "doc": "<p>Retrieve all frames belonging to the habituation phase.</p>\n\n<p>The habituation segment is defined by <code>self.habituation_inds</code>, which\nis set at initialization based on the first trigger.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>to_norm : bool, optional\n    If True, frames are converted to normalized grayscale and mean-centered.\nflip_vertical : bool, optional\n    If True, frames are flipped vertically.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>numpy.ndarray\n    Frames from the habituation phase as either RGB or normalized\n    grayscale, depending on <code>to_norm</code>.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">to_norm</span><span class=\"o\">=</span><span class=\"kc\">True</span>, </span><span class=\"param\"><span class=\"n\">flip_vertical</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.get_next_frame", "modulename": "video_lib", "qualname": "VideoManager.get_next_frame", "kind": "function", "doc": "<p>Read the next frame in sequence from the video.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>flip_vertical : bool, optional\n    If True, the frame is flipped vertically.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>numpy.ndarray or None\n    The next frame as an array, or None if reading fails.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">flip_vertical</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.get_trial", "modulename": "video_lib", "qualname": "VideoManager.get_trial", "kind": "function", "doc": "<p>Extract a time window around a given trigger (trial).</p>\n\n<p>The trial window is centered on the trigger timestamp and extends\n<code>pre</code> frames before and <code>post</code> frames after.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>trial : int\n    Index of the trigger (trial) to extract.\npre : int, optional\n    Number of frames before the trigger to include.\npost : int, optional\n    Number of frames after the trigger to include.\nto_norm : bool, optional\n    If True, frames are converted to normalized grayscale and mean-centered.\nflip_vertical : bool, optional\n    If True, frames are flipped vertically.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>res : numpy.ndarray\n    Extracted frames with shape (pre + post, H, W, 3) for RGB, or\n    (pre + post, H, W) if <code>to_norm</code> is True.\ntrg : numpy.ndarray\n    A 1D array (length equal to number of frames) with a single 1\n    at the trigger index and 0 elsewhere.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">trial</span>, </span><span class=\"param\"><span class=\"n\">pre</span><span class=\"o\">=</span><span class=\"mi\">60</span>, </span><span class=\"param\"><span class=\"n\">post</span><span class=\"o\">=</span><span class=\"mi\">60</span>, </span><span class=\"param\"><span class=\"n\">to_norm</span><span class=\"o\">=</span><span class=\"kc\">False</span>, </span><span class=\"param\"><span class=\"n\">flip_vertical</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.preview_trial", "modulename": "video_lib", "qualname": "VideoManager.preview_trial", "kind": "function", "doc": "<p>Preview a single trial as an OpenCV window animation.</p>\n\n<p>The method extracts a trial window, optionally overlays labels,\nhighlights movement, and allows repeated playback until 'q' is pressed.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>trial_num : int\n    Index of the trial to preview.\npre : int, optional\n    Frames before the trigger to include.\npost : int, optional\n    Frames after the trigger to include.\nshowlabels : bool, optional\n    If True, shows trial, intensity, and PRE/POST labels on the frame.\nrepeat : bool, optional\n    If True, loops the trial playback.\nwindow : str, optional\n    Name of the OpenCV window.\nmovements : bool, optional\n    If True, computes and optionally overlays movement information.\nmovements_overlay : bool, optional\n    If True, overlays motion mask on the video frames.\nylims : tuple, optional\n    Y-axis limits for the movement trace drawn on the frame.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>None\n    The function opens an OpenCV window and blocks until playback ends\n    or 'q' is pressed.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">trial_num</span>,</span><span class=\"param\">\t<span class=\"n\">pre</span><span class=\"o\">=</span><span class=\"mi\">60</span>,</span><span class=\"param\">\t<span class=\"n\">post</span><span class=\"o\">=</span><span class=\"mi\">60</span>,</span><span class=\"param\">\t<span class=\"n\">showlabels</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">repeat</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">window</span><span class=\"o\">=</span><span class=\"s1\">&#39;Frame&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">movements</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">movements_overlay</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">ylims</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">60000</span><span class=\"p\">)</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.previewAllTrials", "modulename": "video_lib", "qualname": "VideoManager.previewAllTrials", "kind": "function", "doc": "<p>Preview all trials in a single mosaic played as a video.</p>\n\n<p>Each trial is resized and arranged in a grid with:</p>\n\n<ul>\n<li>rows = stimulation intensities</li>\n<li>columns = repetitions</li>\n</ul>\n\n<p>The mosaic is then animated over time to show all trials in parallel.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>pre : int, optional\n    Frames before each trigger to include in the trial segments.\npost : int, optional\n    Frames after each trigger to include.\nframe_height : int, optional\n    Height of the mosaic preview window.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>None\n    Opens an OpenCV window and animates the mosaic until 'q' is pressed.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">pre</span><span class=\"o\">=</span><span class=\"mi\">100</span>, </span><span class=\"param\"><span class=\"n\">post</span><span class=\"o\">=</span><span class=\"mi\">100</span>, </span><span class=\"param\"><span class=\"n\">frame_height</span><span class=\"o\">=</span><span class=\"mi\">700</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.previewAllTrials2Video", "modulename": "video_lib", "qualname": "VideoManager.previewAllTrials2Video", "kind": "function", "doc": "<p>Generate and save a mosaic video of all trials.</p>\n\n<p>Similar to <code>previewAllTrials</code>, but instead of showing the mosaic live,\nthis method writes it to a video file on disk.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>pre : int, optional\n    Frames before each trigger to include in the trial segments.\npost : int, optional\n    Frames after each trigger to include.\nframe_height : int, optional\n    Height of the mosaic frames in the saved video.\nvideo_filename : str, optional\n    Output video filename. If None, uses \"<rec>.mp4\".</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>None\n    Writes a video file with the mosaic of all trials.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">pre</span><span class=\"o\">=</span><span class=\"mi\">100</span>, </span><span class=\"param\"><span class=\"n\">post</span><span class=\"o\">=</span><span class=\"mi\">100</span>, </span><span class=\"param\"><span class=\"n\">frame_height</span><span class=\"o\">=</span><span class=\"mi\">700</span>, </span><span class=\"param\"><span class=\"n\">video_filename</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.previewAllTrials2GIF", "modulename": "video_lib", "qualname": "VideoManager.previewAllTrials2GIF", "kind": "function", "doc": "<p>Generate and save a GIF preview of the full trial mosaic.</p>\n\n<p>This method builds the same mosaic representation used by\n<code>previewAllTrials</code>, but then exports it as an optimized GIF using PIL.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>pre : int, optional\n    Frames before each trigger to include in each trial window.\npost : int, optional\n    Frames after each trigger to include.\nframe_height : int, optional\n    Height of the mosaic in pixels.\ngif_filename : str, optional\n    Output GIF filename. If None, uses \"<rec>.gif\".\nresize_factor : float, optional\n    Scale factor applied to the final frames (1.0 = full size, 0.5 = half).\ndither : bool, optional\n    If True, enables Floyd-Steinberg dithering in the palette reduction.\npalette : int, optional\n    Size of the color palette (max 256).</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>None\n    Writes an animated GIF to disk.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">pre</span><span class=\"o\">=</span><span class=\"mi\">100</span>,</span><span class=\"param\">\t<span class=\"n\">post</span><span class=\"o\">=</span><span class=\"mi\">100</span>,</span><span class=\"param\">\t<span class=\"n\">frame_height</span><span class=\"o\">=</span><span class=\"mi\">700</span>,</span><span class=\"param\">\t<span class=\"n\">gif_filename</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">resize_factor</span><span class=\"o\">=</span><span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">dither</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">palette</span><span class=\"o\">=</span><span class=\"mi\">256</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.reset", "modulename": "video_lib", "qualname": "VideoManager.reset", "kind": "function", "doc": "<p>Reset the video position to the first frame.</p>\n\n<p>This is useful when restarting analysis or preview from the beginning.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.gotoframe", "modulename": "video_lib", "qualname": "VideoManager.gotoframe", "kind": "function", "doc": "<p>Seek to a specific frame index in the video.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>i : int\n    Frame index to seek to.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>None</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">i</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.close", "modulename": "video_lib", "qualname": "VideoManager.close", "kind": "function", "doc": "<p>Release the underlying OpenCV VideoCapture resource.</p>\n\n<p>Call this when the VideoManager instance is no longer needed.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.get_valid_trials", "modulename": "video_lib", "qualname": "VideoManager.get_valid_trials", "kind": "function", "doc": "<p>Get indices of valid trials for a given stimulation intensity.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>intensity : int\n    Stimulation intensity label for which to retrieve valid trials.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>list of int\n    Indices of trials that match the requested intensity and are marked\n    as valid in <code>stim_db</code>.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">intensity</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.frame_movements", "modulename": "video_lib", "qualname": "VideoManager.frame_movements", "kind": "function", "doc": "<p>Compute movement between two frames using absolute difference.</p>\n\n<p>Both frames are blurred, subtracted, thresholded, and the number of\nnon-zero pixels in the thresholded image is used as a movement index.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>prev_frame : numpy.ndarray\n    Previous frame (HxW or HxWx3).\ncurr_frame : numpy.ndarray\n    Current frame (HxW or HxWx3).\ngfilt : int, optional\n    Gaussian kernel size used for blurring.\nthr : int, optional\n    Threshold for detecting motion in the difference image.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>thresh_frame : numpy.ndarray\n    Thresholded difference frame, same size as input frames.\nmovement_index : int\n    Number of non-zero pixels in <code>thresh_frame</code>, indicating motion level.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">prev_frame</span>, </span><span class=\"param\"><span class=\"n\">curr_frame</span>, </span><span class=\"param\"><span class=\"n\">gfilt</span><span class=\"o\">=</span><span class=\"mi\">5</span>, </span><span class=\"param\"><span class=\"n\">thr</span><span class=\"o\">=</span><span class=\"mi\">10</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.list_videos", "modulename": "video_lib", "qualname": "VideoManager.list_videos", "kind": "function", "doc": "<p>List all video files in a given directory with a given extension.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>pth : str, optional\n    Path to the directory containing video files.\nverbosity : int, optional\n    If non-zero, prints the found videos to stdout.\next : str, optional\n    File extension to filter for (for example 'avi').</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>list of str\n    List of full paths to video files matching the extension.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">pth</span><span class=\"o\">=</span><span class=\"s1\">&#39;res</span><span class=\"se\">\\\\</span><span class=\"s1\">upright&#39;</span>, </span><span class=\"param\"><span class=\"n\">verbosity</span><span class=\"o\">=</span><span class=\"mi\">0</span>, </span><span class=\"param\"><span class=\"n\">ext</span><span class=\"o\">=</span><span class=\"s1\">&#39;avi&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.phase_scramble_image", "modulename": "video_lib", "qualname": "VideoManager.phase_scramble_image", "kind": "function", "doc": "<p>Apply Fourier phase scrambling to an image.</p>\n\n<p>The magnitude spectrum is preserved while phase is randomized or\nshuffled, which preserves low-level statistics but disrupts semantic\ncontent.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>frame : numpy.ndarray\n    Input image (HxWx3, BGR).\nphase_scrambling_matrix : numpy.ndarray, optional\n    Precomputed phase matrix to reuse for temporal consistency.\nseed : int, optional\n    Random seed for reproducibility when generating new phase matrices.\nto_rgb : bool, optional\n    If True, the output is converted back to 3-channel RGB.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>scrambled_frame_normalized : numpy.ndarray\n    Phase-scrambled image in uint8.\nphase_scrambling_matrix : numpy.ndarray\n    Phase matrix used for scrambling, which can be reused for other frames.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">frame</span>, </span><span class=\"param\"><span class=\"n\">phase_scrambling_matrix</span><span class=\"o\">=</span><span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">to_rgb</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.shuffle_2d_array", "modulename": "video_lib", "qualname": "VideoManager.shuffle_2d_array", "kind": "function", "doc": "<p>Randomly shuffle the elements of a 2D array.</p>\n\n<p>This is used to randomize the phase map while preserving the global\ndistribution of phase values.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>arr : numpy.ndarray\n    Input 2D array.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>numpy.ndarray\n    Shuffled array with the same shape as input.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">arr</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.preview", "modulename": "video_lib", "qualname": "VideoManager.preview", "kind": "function", "doc": "<p>Preview an array of frames in an OpenCV window.</p>\n\n<p>Frames can be either 3D (N, H, W) or 4D (N, H, W, C). Playback runs\nuntil the sequence ends or the user presses 'q'.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>frames : numpy.ndarray\n    Array of frames to display.\nwindow : str, optional\n    Name of the OpenCV window.\nfps : int, optional\n    Frames per second for playback.\nrepeat : bool, optional\n    If True, loops playback when it reaches the end.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>None</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">frames</span>, </span><span class=\"param\"><span class=\"n\">window</span><span class=\"o\">=</span><span class=\"s1\">&#39;Frames&#39;</span>, </span><span class=\"param\"><span class=\"n\">fps</span><span class=\"o\">=</span><span class=\"mi\">20</span>, </span><span class=\"param\"><span class=\"n\">repeat</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.calculate_movement_indices", "modulename": "video_lib", "qualname": "VideoManager.calculate_movement_indices", "kind": "function", "doc": "<p>Compute movement indices for a sequence of frames.</p>\n\n<p>Movement between each pair of consecutive frames is computed using\n<code>frame_movements</code>. The resulting 1D list can be used as a time series\nof motion energy.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>frames : numpy.ndarray\n    4D array of frames with shape (N, H, W, C).</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>list of int\n    Movement index for each frame pair (length N, with the first\n    element set to 0).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">frames</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.draw_plot_on_frame", "modulename": "video_lib", "qualname": "VideoManager.draw_plot_on_frame", "kind": "function", "doc": "<p>Draw a simple line plot of data directly on a video frame.</p>\n\n<p>This is used to overlay movement traces on top of video frames using\npure OpenCV operations.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>frame : numpy.ndarray\n    Current video frame (HxWx3).\ndata_points : list of float or int\n    Data values to plot.\nmax_data_length : int, optional\n    Maximum number of recent data points to display.\nplot_dimensions : tuple of int, optional\n    Size of the plot (width, height) in pixels.\nmargin : int, optional\n    Margin inside the plotting area.\noffset : tuple of int, optional\n    (x, y) position of the plot in the frame. If None, the plot is\n    placed in the bottom right corner.\nymin, ymax : float, optional\n    Explicit minimum and maximum values for scaling. If None, they\n    are inferred from data_points.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>numpy.ndarray\n    Frame with the plot drawn on it.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">frame</span>,</span><span class=\"param\">\t<span class=\"n\">data_points</span>,</span><span class=\"param\">\t<span class=\"n\">max_data_length</span><span class=\"o\">=</span><span class=\"mi\">50</span>,</span><span class=\"param\">\t<span class=\"n\">plot_dimensions</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">margin</span><span class=\"o\">=</span><span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">offset</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ymin</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ymax</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "video_lib.VideoManager.info", "modulename": "video_lib", "qualname": "VideoManager.info", "kind": "function", "doc": "<p>Return a dictionary with summary information about the recording.</p>\n\n<p>The dictionary contains basic video metadata, trigger/trial information,\nand a count of valid and invalid trials per <code>recordings.xlsx</code>.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>dict\n    Information dictionary with keys:\n    - file\n    - recording_name\n    - fps\n    - total_frames\n    - resolution\n    - duration_sec\n    - duration_min\n    - num_trials\n    - first_trigger_frame\n    - last_trigger_frame\n    - intensity_counts\n    - valid_trials\n    - invalid_trials</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();